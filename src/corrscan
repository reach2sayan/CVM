#!/usr/bin/env python3

import argparse
import dataloader as dl
from energyfunctions import F, F_jacobian, F_hessian
import numpy as np
from ase.units import kB
import optimiser as opt
import pandas as pd
from constraints import Constraints
from bounds import CorrBounds
import warnings
import random

def get_uniform_triangular_points(xvalues, yvalues, x1=0, y1=0, x2=-1, y2=1, x3=1, y3=1, num = 10):

    def isInside(x, y, x1=0, y1=0, x2=-1, y2=1, x3=1, y3=1,):

        def area(x1, y1, x2, y2, x3, y3):
            return abs((x1*(y2 - y3) + x2*(y3 - y1) + x3*(y1 - y2))/2.0)

        # Calculate area of triangle ABC
        A = area(x1, y1, x2, y2, x3, y3)
        # Calculate area of triangle PBC
        A1 = area(x, y, x2, y2, x3, y3)
        # Calculate area of triangle PAC
        A2 = area(x1, y1, x, y, x3, y3)
        # Calculate area of triangle PAB
        A3 = area(x1, y1, x2, y2, x, y)
        # Check if sum of A1, A2 and A3
        # is same as A
        if(A == A1 + A2 + A3):
            return True
        else:
            return False


    points = []
    #xx, yy = np.meshgrid(xvalues, yvalues)
    grid = np.meshgrid(xvalues, yvalues)
    grid = np.vstack(list(map(np.ravel, grid))).T

    for x, y in grid:
        if isInside(x,y,x1=x1,y1=y1,x2=x2,y2=y2,x3=x3,y3=y3):
            points.append([x,y])

    return np.array(points)

if __name__ == '__main__':

    np.set_printoptions(suppress=True,precision=2)
    np.random.seed(seed=42)    
    random.seed(42)

    parser = argparse.ArgumentParser()
    parser.add_argument('--eci',
                        default='eci.out', 
                        help="file containing ECI's (default: %(default)s)",
                       )
    parser.add_argument('--vmat', 
                        default='vmat.out',
                        help="file containing the vmatrix (default: %(default)s)",
                       )
    parser.add_argument('--clusters',
                        default='clusters.out',
                        help="file contain the maximal cluster description (default: %(default)s)",
                       )
    parser.add_argument('--kb',
                        default='kb.out',
                        help="file containing the kikuchi-barker coefficients (default: %(default)s)",
                       )
    parser.add_argument('--configcoef',
                        default='configcoef.out',
                        help="file containing coefficient for each subcluster (default: %(default)s)",
                       )
    parser.add_argument('--configs','--config',
                        default='config.out',
                        help="file containing subcluster descriptions (default: %(default)s)",
                       )
    parser.add_argument('--Tmin',
                        type=float,
                        default=0,
                        help="minimum T for phase diagram (default: %(default)s)",
                       )
    parser.add_argument('--Tmax',
                        type=float,
                        default=500.0,
                        help="maximum T for phase diagram (default: %(default)s)",
                       )
    parser.add_argument('--nTemp',
                        type=int,
                        default=11,
                        help="Number of data points between Tmin and Tmax (default: %(default)s)",
                       )
    parser.add_argument('--ncorr',
                        type=int,
                        default=8,
                        help="Number of data points 1-point correlations  (default: %(default)s)",
                       )
    parser.add_argument('--out',
                        default='corrscan_latest.csv',
                        help="Name of the dataframe containing the result of the optimisation"
                       )
    parser.add_argument('--verbose', '-v', action='count', default=0,
                        help="Indicate the verbosity of the fit (default: %(default)s)",
                       )
    parser.add_argument('--maxiter',
                        default=3000,
                        type=int,
                        help="Indicate maximum iterations for the local optimiser (default: %(default)s)",
                       )
    parser.add_argument('--tolerance',
                        default=1e-12,
                        type=float,
                        help="Indicate the acceptable difference between two iterations (default: %(default)s)",
                       )
    parser.add_argument('--global_trials',
                        default=100,
                        type=int,
                        help="Indicate the number of initial point iteration for global minima search (default: %(default)s)",
                       )
    parser.add_argument('--uniform',
                        action='store_true',
                        default=True,
                        help="Use uniform sampling to search global minima (default: %(default)s)",
                       )
    parser.add_argument('--basinhopping',
                        action='store_true',
                        default=False,
                        help="Use basin hopping to search global minima",
                       )
    parser.add_argument('--show_warning',
                        action='store_true',
                        default=False,
                        help="Enables to show warning",
                       )
    parser.add_argument('--log',
                        action='store_true',
                        default=False,
                        help="Enable logging",
                       )
    parser.add_argument('--logfile',
                        default='log.out',
                        help="Filename for the log file (default: %(default)s)"
                       )

    args = parser.parse_args()

    if not args.show_warning:
        warnings.filterwarnings("ignore")

    clusters = dl.read_clusters(args.clusters)
    kb = dl.read_kbcoeffs(args.kb)
    configcoef = dl.read_configcoef(args.configcoef)
    configs = dl.read_configs(args.configs)
    vmat = dl.read_vmatrix(args.vmat)
    eci = dl.read_eci(args.eci)
    outfile = args.out
    MIN_TEMP = args.Tmin
    MAX_TEMP = args.Tmax
    steps = args.nTemp
    NUM_TRIALS = args.global_trials
    num_clusters = len(clusters)   
    ncorr = args.ncorr

    results_corrscan = pd.DataFrame(columns = ['T', '1-point_corr', '2-point_corr', 'F','corrs'])

    constraints = Constraints(clusters, configcoef, vmat)
    bounds = CorrBounds(num_clusters)

    options = {'verbose' : args.verbose,
               'maxiter' : args.maxiter,
               'xtol'    : args.tolerance,
               'initial_constr_penalty' : 10
              }

    xvalues = np.linspace(-1+np.finfo(float).eps,1-np.finfo(float).eps,ncorr)
    yvalues = np.linspace(-1+np.finfo(float).eps,1-np.finfo(float).eps,ncorr)
    singlet_doublet_pairs = get_uniform_triangular_points(xvalues, yvalues, 
                                                          x1=0, y1=-1, 
                                                          x2=-1, y2=1,
                                                          x3=1, y3=1,
                                                          num=ncorr
                                                         )
    singlet_doublet_pairs = np.append(singlet_doublet_pairs,
                                      [[0,-1+np.finfo(float).eps]],
                                      axis=0)

    import matplotlib.pyplot as plt
    plt.style.use('default')
    plt.scatter(singlet_doublet_pairs[:, 0], singlet_doublet_pairs[:, 1], s=5)
    plt.savefig('NN-grid.png',dpi=300)

    for temp in np.linspace(MIN_TEMP, MAX_TEMP, num=steps):
        for FIXED_CORR_1, FIXED_CORR_2 in singlet_doublet_pairs:
            print(f"T: {temp} CORR_1: {FIXED_CORR_1}, CORR_2: {FIXED_CORR_2}")
            constraints_corrscan = constraints.get_constraints_corrscan(FIXED_CORR_1, FIXED_CORR_2)
            bounds_corrscan = bounds.get_corrscan_bounds(FIXED_CORR_1,FIXED_CORR_2)

            result = opt.fit(F=F,
                             vmat=vmat, kb=kb, 
                             clusters=clusters, 
                             configs=configs, 
                             configcoef=configcoef,
                             temp=temp, 
                             eci=eci, 
                             options=options,
                             jac=F_jacobian,
                             hess=F_hessian,
                             NUM_TRIALS=NUM_TRIALS,
                             FIXED_CORR_1=FIXED_CORR_1,
                             FIXED_CORR_2=FIXED_CORR_2,
                             bounds=bounds_corrscan,
                             constraints=constraints_corrscan,
                             num_clusters=num_clusters,
                             NN=True
                            )

            print(f"Corrs: {result.x} ENERGY: {result.fun}")
            for cluster_idx, _ in clusters.items():
                print(np.matmul(vmat[cluster_idx],result.x))

            results_corrscan = results_corrscan.append({'T' : temp, 
                                                        '1-point_corr' : FIXED_CORR_1, 
                                                        '2-point_corr': FIXED_CORR_2,
                                                        'F' : result.fun, 
                                                        'corrs': result.x,
                                                       }, 
                                                       ignore_index = True
                                                      )

    corrcols = [f'corr {i}' for i in range(num_clusters)]
    results_corrscan[corrcols] = pd.DataFrame(results_corrscan.corrs.tolist(), 
                                              index = results_corrscan.index,
                                             )
    results_corrscan.drop(['corrs'],axis=1,inplace=True)

    results_corrscan.to_csv(outfile,index=False)
    
    #TODO: Add handler for plotting phase diagram
    #plot_tool.plot_phasediagram(results_phasediagram)
